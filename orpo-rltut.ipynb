{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\n# Load secrets\nuser_secrets = UserSecretsClient()\n\n# Hugging Face Login\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)\n\n# Weights & Biases Login\nwandb_api_key = user_secrets.get_secret(\"wandb_token\")\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key \nwandb.login()  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T10:57:02.581777Z","iopub.execute_input":"2025-03-21T10:57:02.582075Z","iopub.status.idle":"2025-03-21T10:57:09.325508Z","shell.execute_reply.started":"2025-03-21T10:57:02.582053Z","shell.execute_reply":"2025-03-21T10:57:09.324772Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mishitas2365\u001b[0m (\u001b[33mishitas2365-indian-institute-of-technology-indore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"!pip install -qqq -U transformers datasets accelerate peft trl bitsandbytes wandb --progress-bar off","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T10:57:52.383198Z","iopub.execute_input":"2025-03-21T10:57:52.383718Z","iopub.status.idle":"2025-03-21T10:58:52.320204Z","shell.execute_reply.started":"2025-03-21T10:57:52.383691Z","shell.execute_reply":"2025-03-21T10:58:52.318921Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import gc\nimport os\n\nimport torch\nimport wandb\nfrom datasets import load_dataset\nfrom google.colab import userdata\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n)\nfrom trl import ORPOConfig, ORPOTrainer, setup_chat_format\n\n# Model\nbase_model = \"meta-llama/Llama-3.2-3B-Instruct\"\nnew_model = \"OrpoLlama-3.2-3B-Instruct\"\n\n\n# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T10:58:52.321928Z","iopub.execute_input":"2025-03-21T10:58:52.322282Z","iopub.status.idle":"2025-03-21T10:59:25.325756Z","shell.execute_reply.started":"2025-03-21T10:58:52.322246Z","shell.execute_reply":"2025-03-21T10:59:25.324991Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\ntokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T10:59:36.193411Z","iopub.execute_input":"2025-03-21T10:59:36.194136Z","iopub.status.idle":"2025-03-21T11:00:18.911938Z","shell.execute_reply.started":"2025-03-21T10:59:36.194091Z","shell.execute_reply":"2025-03-21T11:00:18.911166Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443510df34e846d1b8caef80a660c539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69255e58d8f14b96bc3fcb79ed6f9d1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422ffcfd4e5f463bb689351f71c10ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a202d4f0da6748dd88444e0fb65acd66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426c5be877d14bfd8f7b1ee40c078a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f73237f0a945a8be28c6a9917acba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76291b4b2b404962afb2e7a65417b39f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d60dc116f549eead07a25927702ffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9025751d0ead41a1b9fb9addae9b5361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7d996796c04f3f90c8cd130fed4903"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=42).select(range(500)) # Only use 500 samples for quick demo\n\ndef format_chat_template(row):\n    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= os.cpu_count(),\n)\ndataset = dataset.train_test_split(test_size=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T11:01:07.551328Z","iopub.execute_input":"2025-03-21T11:01:07.551651Z","iopub.status.idle":"2025-03-21T11:01:12.552135Z","shell.execute_reply.started":"2025-03-21T11:01:07.551622Z","shell.execute_reply":"2025-03-21T11:01:12.551206Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb9bcdeaef24e3eac93c94532c9e52d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/127M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c21171e82e924b31985a1d40dd41c5fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/44245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e485ea55f95940538b2438aabcf11894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99174181bd8d44e5b9475b761fed39c1"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"orpo_args = ORPOConfig(\n    learning_rate=8e-6,\n    lr_scheduler_type=\"linear\",\n    max_length=1024,\n    max_prompt_length=512,\n    beta=0.1,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_8bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    report_to=\"wandb\",\n    output_dir=\"./results/\",\n)\n\n\ntrainer = ORPOTrainer(\n    model=model,\n    args=orpo_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    processing_class=tokenizer,\n)\n\ntrainer.train()\ntrainer.save_model(new_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T11:01:18.089396Z","iopub.execute_input":"2025-03-21T11:01:18.089727Z","iopub.status.idle":"2025-03-21T12:11:29.175853Z","shell.execute_reply.started":"2025-03-21T11:01:18.089700Z","shell.execute_reply":"2025-03-21T12:11:29.174822Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/495 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87d90aebc3d476c8d1d8379309f2260"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/495 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"760edc730d7d464faeb3408e04c2ef56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/495 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e8f05e6fbb546b0be9094876f5cb0d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ddb43d8bd3546c2aab636f6771959c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f20138885ee4d9e8704705a85da0903"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f4cfd67aad47daa764444c433d05be"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250321_110122-pkqiilep</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface/runs/pkqiilep' target=\"_blank\">./results/</a></strong> to <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface/runs/pkqiilep' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/huggingface/runs/pkqiilep</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62/62 1:08:46, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/rejected</th>\n      <th>Logps/chosen</th>\n      <th>Logits/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Nll Loss</th>\n      <th>Log Odds Ratio</th>\n      <th>Log Odds Chosen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>13</td>\n      <td>7.789800</td>\n      <td>1.954201</td>\n      <td>7.690800</td>\n      <td>0.650000</td>\n      <td>0.390000</td>\n      <td>-0.143365</td>\n      <td>-0.229684</td>\n      <td>0.833333</td>\n      <td>0.086318</td>\n      <td>-2.296835</td>\n      <td>-1.433653</td>\n      <td>-0.440120</td>\n      <td>-0.066296</td>\n      <td>1.877920</td>\n      <td>-0.451141</td>\n      <td>0.973508</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>6.485900</td>\n      <td>1.874050</td>\n      <td>7.652800</td>\n      <td>0.653000</td>\n      <td>0.392000</td>\n      <td>-0.133803</td>\n      <td>-0.217026</td>\n      <td>0.833333</td>\n      <td>0.083223</td>\n      <td>-2.170259</td>\n      <td>-1.338030</td>\n      <td>-0.508268</td>\n      <td>-0.127148</td>\n      <td>1.800089</td>\n      <td>-0.457762</td>\n      <td>0.950766</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>5.534200</td>\n      <td>1.823692</td>\n      <td>7.752200</td>\n      <td>0.645000</td>\n      <td>0.387000</td>\n      <td>-0.127887</td>\n      <td>-0.209329</td>\n      <td>0.833333</td>\n      <td>0.081442</td>\n      <td>-2.093285</td>\n      <td>-1.278866</td>\n      <td>-0.552641</td>\n      <td>-0.164237</td>\n      <td>1.750731</td>\n      <td>-0.461167</td>\n      <td>0.938845</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>5.998600</td>\n      <td>1.798741</td>\n      <td>7.749200</td>\n      <td>0.645000</td>\n      <td>0.387000</td>\n      <td>-0.125074</td>\n      <td>-0.205618</td>\n      <td>0.833333</td>\n      <td>0.080544</td>\n      <td>-2.056181</td>\n      <td>-1.250742</td>\n      <td>-0.575668</td>\n      <td>-0.183196</td>\n      <td>1.726450</td>\n      <td>-0.463011</td>\n      <td>0.932185</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:241: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:241: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Flush memory\ngc.collect()\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Reload tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(base_model)\ntokenizer.chat_template = None\nfp16_model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nfp16_model, tokenizer = setup_chat_format(fp16_model, tokenizer)\n\n# Merge adapter with base model\nmodel = PeftModel.from_pretrained(fp16_model, new_model)\nmodel = model.merge_and_unload()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T12:19:31.150305Z","iopub.execute_input":"2025-03-21T12:19:31.150613Z","iopub.status.idle":"2025-03-21T12:19:43.348025Z","shell.execute_reply.started":"2025-03-21T12:19:31.150588Z","shell.execute_reply":"2025-03-21T12:19:43.347176Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"befa161eee9042afae960b712538a933"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T12:19:55.282169Z","iopub.execute_input":"2025-03-21T12:19:55.282591Z","iopub.status.idle":"2025-03-21T12:22:44.695521Z","shell.execute_reply.started":"2025-03-21T12:19:55.282556Z","shell.execute_reply":"2025-03-21T12:22:44.694315Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba9ab6035a94df0a55e2d3818ff9aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15255f8731a24b1f941e21cc0cce1444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df780c9c49724fbc982de3c08edcea10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0206c91b57ce40069ba2f8f66420420b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee90c0321f754581892235c4e2d9d4b5"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ishitas2365/OrpoLlama-3.2-3B-Instruct/commit/2b24163d89f3b5872e96bf3f6361ed1df86c6b97', commit_message='Upload tokenizer', commit_description='', oid='2b24163d89f3b5872e96bf3f6361ed1df86c6b97', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ishitas2365/OrpoLlama-3.2-3B-Instruct', endpoint='https://huggingface.co', repo_type='model', repo_id='ishitas2365/OrpoLlama-3.2-3B-Instruct'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":17}]}